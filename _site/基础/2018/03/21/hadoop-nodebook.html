<!DOCTYPE html>
<html lang="en">

  <head>

    <!-- Non social metatags -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="theme-color" content="#157878">

    

    <title>my hadoop2 notebook</title>

    
      <!-- Update your html tag to include the itemscope and itemtype attributes. -->
<html itemscope itemtype="http://schema.org/Article">












<!-- Place this data between the <head> tags of your website -->

<meta name="description" content="Hadoop2 学习笔记 1.概述 Hadoop的两个核心组成部分： 1）分布式文件系统-HDFS； 2）分布式数据处理架构-MapReduce。MR功能实现了将单个任务打碎，并将碎片任务（Map）发送到多个节点上，之后再以单个数据集的形式加载（Reduce）到数据仓库。" />





<!-- Schema.org markup for Google+ -->
<meta itemprop="name" content="my hadoop2 notebook">
<meta itemprop="description" content="Hadoop2 学习笔记 1.概述 Hadoop的两个核心组成部分： 1）分布式文件系统-HDFS； 2）分布式数据处理架构-MapReduce。MR功能实现了将单个任务打碎，并将碎片任务（Map）发送到多个节点上，之后再以单个数据集的形式加载（Reduce）到数据仓库。">

  <meta itemprop="image" content="http://localhost:4000/">


<!-- Twitter Card data -->
<meta name="twitter:card" content="summary_large_image">



<meta name="twitter:title" content="my hadoop2 notebook">
<meta name="twitter:description" content="Hadoop2 学习笔记 1.概述 Hadoop的两个核心组成部分： 1）分布式文件系统-HDFS； 2）分布式数据处理架构-MapReduce。MR功能实现了将单个任务打碎，并将碎片任务（Map）发送到多个节点上，之后再以单个数据集的形式加载（Reduce）到数据仓库。">



<!-- Twitter summary card with large image must be at least 280x150px -->

  <meta name="twitter:image:src" content="http://localhost:4000/">
  <meta property="twitter:image" content="http://localhost:4000/">

<meta property="twitter:url" content="http://localhost:4000//%E5%9F%BA%E7%A1%80/2018/03/21/hadoop-nodebook.html">

<!-- Open Graph data -->
<meta property="og:title" content="my hadoop2 notebook" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:4000//%E5%9F%BA%E7%A1%80/2018/03/21/hadoop-nodebook.html" />

  <meta property="og:image" content="http://localhost:4000/" />

<meta property="og:description" content="Hadoop2 学习笔记 1.概述 Hadoop的两个核心组成部分： 1）分布式文件系统-HDFS； 2）分布式数据处理架构-MapReduce。MR功能实现了将单个任务打碎，并将碎片任务（Map）发送到多个节点上，之后再以单个数据集的形式加载（Reduce）到数据仓库。" />
<meta property="og:site_name" content="liuChR's blog" />

  <meta property="article:published_time" content="2018-03-21T05:00:00+08:00" />














  
    <meta property="article:tag" content="fromSRE">
  
    <meta property="article:tag" content="Hadoop">
  





  
    <meta property="article:tag" content="基础">
  




    

    <link rel="canonical" href="http://localhost:4000/%E5%9F%BA%E7%A1%80/2018/03/21/hadoop-nodebook.html">

    

    <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
    <meta name="robots" content="noarchive">

    <!-- <link rel="alternate" media="only screen and (max-width: 640px)" href="">
    <link rel="alternate" media="handheld" href=""> -->


    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    

    
      <a class="site-title" href="/">liuChR&#39;s blog</a>
    

    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
              
              
            
          
            
            
              
                <a class="page-link" href="/about.html">About</a>
              
            
          
            
            
              
                <a class="page-link" href="/contact.html">Contact</a>
              
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    
    
    

    <section class="page-header">
      <h1 class="project-name">my hadoop2 notebook</h1>
      <h2 class="project-tagline"></h2>
      
      <!-- Post tagline -->
      
        <h2 class="project-date">
        <time datetime="2018-03-21T05:00:00+08:00" itemprop="datePublished">
          
          Mar 21, 2018
        </time>
        
        
        </h2>
      
      <!-- End: Post tagline -->
    </section>

    <section class="main-content">

      <article itemscope itemtype="http://schema.org/BlogPosting">

  <!-- <header class="post-header">
    <h1 class="post-title" itemprop="name headline">my hadoop2 notebook</h1>
    <p class="post-meta">
      <time datetime="2018-03-21T05:00:00+08:00" itemprop="datePublished">
        
        Mar 21, 2018
      </time>
      </p>
  </header> -->

  <div itemprop="articleBody">
    <h1 id="hadoop2-学习笔记">Hadoop2 学习笔记</h1>
<h2 id="1概述">1.概述</h2>
<h3 id="hadoop的两个核心组成部分">Hadoop的两个核心组成部分：</h3>
<p>1）分布式文件系统-HDFS；<br />
2）分布式数据处理架构-MapReduce。MR功能实现了将单个任务打碎，并将碎片任务（Map）发送到多个节点上，之后再以单个数据集的形式加载（Reduce）到数据仓库。</p>

<h4 id="1hdfs-两个版本的差异">1.HDFS 两个版本的差异</h4>
<ul>
  <li>在一版本中，一个集群中仅有一个NameNode。一个集群中仅有一个SecondaryNameNode定期（checkpoint）保存NameNode数据，即SecondaryNameNode中存储的是上一次checkpoint之后的NameNode。checkpoint node默认在主节点，也可以放到其他节点上，但还是归主节点管理。对于单点NameNode坏了的话，可以通过SecondaryNameNode来恢复上一次checkpoint时候的数据，或者是写NameNode的时候就往第三方上写一份，用于备份恢复。</li>
  <li>在二版本中，NameNode节点可以有备NameNode，也可以没有。</li>
</ul>

<h4 id="2mapreduce">2.MapReduce</h4>
<p>占用20%-30%磁盘空间<br />
Map：将任务分解为多个子任务执行<br />
Reduce：将这些子任务的处理结果进行汇总<br />
![Alt text](http://ww4.sinaimg.cn/large/0060lm7Tly1fpo91ssghjj30ld07675l.jpg
 “”)</p>

<h4 id="3apache-hadoop-与-cdh">3.Apache Hadoop 与 CDH</h4>
<p>Hadoop1对应CDH3 <br />
Hadoop2对应CDH4</p>

<h4 id="另">另，</h4>
<p>与Spark相比，中间结果存储在磁盘中，而spark的中间结果存储在内存中，因此，spark更快</p>

<h2 id="2hadoop1-架构">2.Hadoop1 架构</h2>
<p>Hadoop1集群中的节点类型分为：
![Alt text](http://ww2.sinaimg.cn/large/0060lm7Tly1fpo96uut5lj30wo0fqmy9.jpg
“”)
1）HDFS：</p>
<ul>
  <li>NameNode记录元数据（记录文件如何分割成数据块，以及存储数据块的数据节点的信息；对内存和I/O进行集中管理）</li>
  <li>DataNode负责将HDFS数据块读写到本地文件系统</li>
  <li>当client端有读写请求时，NameNode会告诉client去哪个DataNode进行操作，&lt;font color=#0099ff&gt;client会直接与这个DataNode进行读写访问&lt;/font&gt;</li>
</ul>

<p>2）MR：</p>
<ul>
  <li>JobTracker负责为所执行任务（Map任务和Reduce任务）分配指定的节点主机，监控所允许的任务并进行重启。</li>
  <li>TaskTracker需要与JobTracker进行定时心跳，若JobTracker不能准时获取TaskTracker的信息，则认为该TaskTracker节点坏了，JobTracker会将任务重新分配给其他从节点</li>
  <li>&lt;font color=#0099ff&gt;client端和JobTracker通信，不直接和TaskTracker连接 &lt;/font&gt;</li>
</ul>

<h3 id="1hdfs-结构">1.HDFS 结构</h3>
<h4 id="11-namenode">1.1 NameNode</h4>
<p>![Alt text](http://ww2.sinaimg.cn/large/0060lm7Tly1fpo9e1soinj30cb077mx7.jpg
“”)</p>
<ul>
  <li>在checkpoint的时候，edit文件内容会合并到fsimage中。在Hadoop1中，SecondaryNameNode负责checkpoint工作。checkpoint的具体过程如下：</li>
</ul>

<p>![Alt text](http://ww3.sinaimg.cn/large/0060lm7Tly1fpo9evs7n1j30fm0fcn03.jpg
“”)</p>
<ul>
  <li>fsimage和edits文件都是经过序列化的，在NameNode启动的时候，它会将fsimage文件中的内容加载到内存中，之后再执行edits文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。</li>
  <li>edits预写入式的日志，并且会接受执行成功或失败的结果。edits只记录对于元数据的改变的操作，读操作不记录。</li>
</ul>

<h4 id="12-datanode">1.2 DataNode</h4>
<p>HDFS机制将每个文件分割成一个或多个大小相等的数据块（Block，默认64M），每个Block会存储在一个或多个DataNode上，默认复制因子为3。如果某个节点坏了，NameNode发现数据块的拷贝数低于设定值，会增加数据块；当节点恢复，NameNode发现数据块的拷贝数高于设定值，会删除多余的。</p>

<h4 id="13-读hdfs操作">1.3 读HDFS操作</h4>
<p><img src="http://ww2.sinaimg.cn/large/0060lm7Tly1fpo9htoeu7j30l50faq45.jpg" alt="" /></p>
<h4 id="14-写hdfs操作">1.4 写HDFS操作</h4>
<p>同步写，必须等3、4成功，才算写成功
<img src="http://ww4.sinaimg.cn/large/0060lm7Tly1fpo9igb9oqj30l60fejt2.jpg" alt="" /></p>

<h3 id="2mr-结构">2.MR 结构</h3>
<h4 id="21-namenode">2.1 NameNode</h4>
<ul>
  <li>TaskTracker定期向JobTracker发送心跳信号，这部分的数据流量非常小</li>
  <li>客户端应用主要与JobTracker和HDFS通讯，但不直接和TaskTracker进行通讯</li>
  <li>MapReduce的主要网络数据流量是Shuffle阶段的TaskTracker产生的</li>
</ul>

<p>MapReduce按以下步骤执行应用程序：<br />
1）客户端向JobTracker提交一个应用程序<br />
2）JobTracker确定整个应用程序所需的处理资源：从NameNode获取所需的文件名和数据块的位置，计算处理所有数据所需的Map和Reduce任务数<br />
3）JobTracker查看所有从节点的状态；并将要执行的Map和Reduce任务排队等待<br />
4）当从节点有可用Slot时，Map任务将被部署到这个从节点。Map任务使用的数据是存储同一个从节点的<br />
5）JobTracker监控任务的进度；如果任务失败或者节点出错，任务会在下一个可用的Slot上重启；如果同一任务失败4次（默认值），该Job就失败了<br />
6）Map任务完成后，Reduce任务处理Map产生的中间结果<br />
7）Reduce任务将结果返回客户端</p>

<p>对于第4点，HDFS以数据块形式存储数据，不关心数据块的内容。这样如果Map处理的数据记录跨越了两个数据块，如何处理？为此，HDFS引入了Input Split概念，以对数据块中的数据进行逻辑表示。如下：
<img src="http://ww2.sinaimg.cn/large/0060lm7Tly1fppcgfyktej30m708xjs1.jpg" alt="" />
如果数据记录位于一个数据块中，Input Split可表示完整的数据记录集；若数据记录跨两个数据块，Input Split中会包含第二个数据块的位置以及所需完整数据的偏移量。<br />
Reduce是处理Map后的结果，具体在哪个节点（a/b/c/…..）上处理，是由MR分资源确定的，对我是透明的</p>

<h2 id="3hadoop1-环境搭建">3.Hadoop1 环境搭建</h2>
<p>两台为例，
<img src="http://ww1.sinaimg.cn/large/0060lm7Tly1fppcif9nwsj30kt0dz767.jpg" alt="" /></p>

<table>
  <thead>
    <tr>
      <th>ip</th>
      <th>hostname</th>
      <th>角色</th>
      <th>进程</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10.221.155.43</td>
      <td>vm-kvm10094-app</td>
      <td>master</td>
      <td>Namenode SecondaryNamenode JobTracker</td>
    </tr>
    <tr>
      <td>10.221.155.44</td>
      <td>vm-kvm10095-app</td>
      <td>slave</td>
      <td>Datanode TaskTracker</td>
    </tr>
  </tbody>
</table>

<p>安装hadoop，hadoop-1.2.1，解压安装在/opt/app/hadoop。
安装jdk1.7
两台机器配互信
hadoop的配置文件在/opt/app/hadoop/conf中，有，
<img src="http://ww4.sinaimg.cn/large/0060lm7Tly1fppcn6t3qbj306x09wt8q.jpg" alt="" /><br />
集群参数的配置主要是通过几个配置文件来完成，这些配置文件位于conf目录：</p>
<ul>
  <li>hadoop-env.sh：用来定义Hadoop环境变量的Shell脚本</li>
  <li>core-site.xml：定义所有Hadoop进程和客户端相关的参数</li>
  <li>hdfs-site.xml：定义所有HDFS进程和客户端相关的参数</li>
  <li>mapred-site.xml：定义与MapReduce进程和客户端相关的参数</li>
  <li>log4j.properties：Java属性文件，包含所有日志配置信息</li>
  <li>hadoop-policy.xml：定义有权限向MapReduce提交作业的用户或组</li>
  <li>mapred-queue-acls.xml：对不同的队列实现不同用户的提交权限</li>
</ul>

<p>另有几个可选的配置文件：</p>
<ul>
  <li>master：列出由换行符分隔的、运行SecondaryNameNode的机器名</li>
  <li>slaves：列出由换行符分隔的、运行DataNode/TaskTracker进程的机器名</li>
  <li>fair-scheduler.xml：定义MapReduce插件Fair Scheduler任务调度的资源池和设置</li>
  <li>capacity-scheduler.xml：定义MapReduce插件Capacity Scheduler任务调度的队列和设置</li>
  <li>dfs.include：列出由换行符分隔的、允许连接NameNode的机器名</li>
  <li>dfs.exclude：列出由换行符分隔的、禁止连接NameNode的机器名</li>
</ul>

<p>修改hadoop-env.sh中的export JAVA_HOME=/opt/app/jdk。<br />
修改conf目录中以下配置文件：</p>
<ul>
  <li>core-site.xml：核心配置文件</li>
  <li>hdfs-site.xml：HDFS配置文件</li>
  <li>mapred-site.xml：MapReduce配置文件</li>
</ul>

<p>配置Hadoop — core-site.xml<br />
vi conf/core-site.xml</p>
<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&lt;</span><span class="nx">configuration</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="nx">property</span><span class="o">&gt;</span>
       <span class="o">&lt;</span><span class="nx">name</span><span class="o">&gt;</span><span class="nx">hadoop</span><span class="p">.</span><span class="nx">tmp</span><span class="p">.</span><span class="nx">dir</span><span class="o">&lt;</span><span class="sr">/name</span><span class="err">&gt;
</span>       <span class="o">&lt;</span><span class="nx">value</span><span class="o">&gt;</span><span class="sr">/home/</span><span class="nx">hadoop</span><span class="o">/</span><span class="nx">hadoop1</span><span class="o">/</span><span class="nx">tmp</span><span class="o">&lt;</span><span class="sr">/value</span><span class="err">&gt;
</span>    <span class="o">&lt;</span><span class="sr">/property</span><span class="err">&gt;
</span>    <span class="o">&lt;</span><span class="nx">property</span><span class="o">&gt;</span>
       <span class="o">&lt;</span><span class="nx">name</span><span class="o">&gt;</span><span class="nx">fs</span><span class="p">.</span><span class="k">default</span><span class="p">.</span><span class="nx">name</span><span class="o">&lt;</span><span class="sr">/name</span><span class="err">&gt;
</span>       <span class="o">&lt;</span><span class="nx">value</span><span class="o">&gt;</span><span class="nx">hdfs</span><span class="p">:</span><span class="c1">//vm-kvm10094-app:8020&lt;/value&gt;   也就是listen的端口，用于slave节点、client来连接</span>
    <span class="o">&lt;</span><span class="sr">/property</span><span class="err">&gt;
</span><span class="o">&lt;</span><span class="sr">/configuration</span><span class="err">&gt;
</span></code></pre></div></div>
<p>其中使用了一个不存在的目录，可以使用mkdir命令事先创建该目录。</p>

<p>配置Hadoop — hdfs-site.xml<br />
vi hdfs-site.xml</p>
<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&lt;</span><span class="nx">configuration</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="nx">property</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nx">name</span><span class="o">&gt;</span><span class="nx">dfs</span><span class="p">.</span><span class="nx">replication</span><span class="o">&lt;</span><span class="sr">/name</span><span class="err">&gt;
</span>        <span class="o">&lt;</span><span class="nx">value</span><span class="o">&gt;</span><span class="mi">3</span><span class="o">&lt;</span><span class="sr">/value&gt;   复制因子，需要小于实际slave节点</span><span class="err">数
</span>    <span class="o">&lt;</span><span class="sr">/property</span><span class="err">&gt;
</span><span class="o">&lt;</span><span class="sr">/configuration</span><span class="err">&gt;
</span></code></pre></div></div>

<p>配置Hadoop — mapred-site.xml<br />
vi conf/mapred-site.xml</p>
<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&lt;</span><span class="nx">configuration</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="nx">property</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nx">name</span><span class="o">&gt;</span><span class="nx">mapred</span><span class="p">.</span><span class="nx">job</span><span class="p">.</span><span class="nx">tracker</span><span class="o">&lt;</span><span class="sr">/name</span><span class="err">&gt;
</span>        <span class="o">&lt;</span><span class="nx">value</span><span class="o">&gt;</span><span class="nx">vm</span><span class="o">-</span><span class="nx">kvm10094</span><span class="o">-</span><span class="nx">app</span><span class="p">:</span><span class="mi">8021</span><span class="o">&lt;</span><span class="sr">/value&gt;  也就是listen的端口，用于slave节点、client来连</span><span class="err">接
</span>    <span class="o">&lt;</span><span class="sr">/property</span><span class="err">&gt;
</span><span class="o">&lt;</span><span class="sr">/configuration</span><span class="err">&gt;
</span></code></pre></div></div>

<p>vi masters<br />
vm-kvm10094-app</p>

<p>vi slaves<br />
vm-kvm10095-app</p>

<p>启动，<br />
在master节点上，HDFS使用前，需要执行格式化NameNode（仅第一次的时候需要），hadoop namenode -format。格式化的目的是在NameNode上创建初始的原数据，创建空的fsimage和edits文件，并为DataNode随机产生storgeID。当DataNode第一次连接NameNode时会接受这个storageID，之后他会拒绝与其他NameNode连接。如需重新格式化NameNode，必须将DataNode的数据和StorageID全部删除。或者是可以尝试将之前的name目录下所有文件cp到新的name目录下。接下来看下面的，也是关于格式化NameNode的，</p>
<ul>
  <li>格式化操作会在NameNode数据目录（即dfs.name.dir指定的本地系统路径）的</li>
</ul>

  </div>

  
</article>


      <footer class="site-footer">
        <!-- SVG icons from https://iconmonstr.com -->

        <!-- Github icon -->
        <span class="my-span-icon">
          <a href="" aria-label="'s GitHub" title="'s GitHub">
            <svg class="my-svg-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
          </a>
        </span>

        <!-- Twitter icon -->
        <span class="my-span-icon">
          <a href="https://twitter.com/" aria-label="'s Twitter" title="'s Twitter">
            <svg class="my-svg-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 0c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm6.066 9.645c.183 4.04-2.83 8.544-8.164 8.544-1.622 0-3.131-.476-4.402-1.291 1.524.18 3.045-.244 4.252-1.189-1.256-.023-2.317-.854-2.684-1.995.451.086.895.061 1.298-.049-1.381-.278-2.335-1.522-2.304-2.853.388.215.83.344 1.301.359-1.279-.855-1.641-2.544-.889-3.835 1.416 1.738 3.533 2.881 5.92 3.001-.419-1.796.944-3.527 2.799-3.527.825 0 1.572.349 2.096.907.654-.128 1.27-.368 1.824-.697-.215.671-.67 1.233-1.263 1.589.581-.07 1.135-.224 1.649-.453-.384.578-.87 1.084-1.433 1.489z"/></svg>
          </a>
        </span>

        <!-- RSS icon -->
        
        <!-- Contact icon -->
        
        

      </footer>
    </section>

    
  </body>
</html>
